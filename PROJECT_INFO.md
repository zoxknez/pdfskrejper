# PDF Scraper - Kompletna Aplikacija âœ…

## ğŸ‰ Aplikacija je uspeÅ¡no kreirana!

### ğŸ“ Struktura Projekta

```
pdfskrajpovanje/
â”‚
â”œâ”€â”€ ğŸ“‚ config/                  # Konfiguracija
â”‚   â”œâ”€â”€ __init__.py            # Init fajl
â”‚   â”œâ”€â”€ settings.py            # Globalne postavke
â”‚   â””â”€â”€ sources.py             # Konfiguracija izvora (arXiv, Gutenberg, itd.)
â”‚
â”œâ”€â”€ ğŸ“‚ scrapers/               # Scraping moduli
â”‚   â”œâ”€â”€ __init__.py           
â”‚   â”œâ”€â”€ base_scraper.py       # Bazna klasa za sve scrapere
â”‚   â”œâ”€â”€ books_scraper.py      # Scraper za knjige
â”‚   â”œâ”€â”€ research_scraper.py   # Scraper za nauÄne radove
â”‚   â””â”€â”€ magazine_scraper.py   # Scraper za Äasopise
â”‚
â”œâ”€â”€ ğŸ“‚ utils/                  # PomoÄ‡ni moduli
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py             # Logging sa Rich formatiranjem
â”‚   â”œâ”€â”€ downloader.py         # Async PDF downloader
â”‚   â””â”€â”€ validators.py         # Validacija URL-ova i PDF-ova
â”‚
â”œâ”€â”€ ğŸ“‚ ui/                     # KorisniÄki interfejs
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ menu.py               # Interaktivni meni sa Rich
â”‚
â”œâ”€â”€ ğŸ“‚ venv/                   # Python virtualno okruÅ¾enje
â”œâ”€â”€ ğŸ“‚ storage/                # Crawlee storage
â”œâ”€â”€ ğŸ“‚ logs/                   # Log fajlovi
â”œâ”€â”€ ğŸ“‚ downloaded_pdfs/        # Preuzeti PDF-ovi (organizovano po kategorijama)
â”‚   â”œâ”€â”€ books/
â”‚   â”œâ”€â”€ research/
â”‚   â”œâ”€â”€ magazines/
â”‚   â””â”€â”€ documents/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                 # Glavni ulazni fajl
â”œâ”€â”€ ğŸ“„ example.py              # Primer upotrebe
â”œâ”€â”€ ğŸ“„ test_basic.py           # Osnovni testovi
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python zavisnosti
â”œâ”€â”€ ğŸ“„ .env                    # Environment varijable
â”œâ”€â”€ ğŸ“„ .env.example            # Primer .env fajla
â”œâ”€â”€ ğŸ“„ .gitignore              # Git ignore fajl
â”œâ”€â”€ ğŸ“„ README.md               # Glavna dokumentacija
â”œâ”€â”€ ğŸ“„ QUICKSTART.md           # Brzi vodiÄ
â””â”€â”€ ğŸ“„ setup.ps1               # Setup skripta
```

## ğŸš€ Glavne Funkcionalnosti

### âœ… Implementirano

1. **Crawlee-Python Framework**
   - Koristi najnoviju verziju Crawlee (1.0.0)
   - Playwright browser za dinamiÄki scraping
   - Async operacije za bolje performanse

2. **Kategorije Dokumenata**
   - ğŸ“š Knjige (Project Gutenberg, Open Library)
   - ğŸ”¬ NauÄni radovi (arXiv, PubMed Central, SSRN)
   - ğŸ“° ÄŒasopisi (Internet Archive)
   - ğŸ“„ Custom dokumenti

3. **Automatsko Preuzimanje**
   - Async download sa kontrolom konkurentnosti
   - Retry mehanizam
   - Validacija PDF fajlova
   - Automatsko organizovanje po kategorijama

4. **Interaktivni UI**
   - Rich formatiranje u terminalu
   - Boje i tabele
   - Progress tracking
   - Intuitivne poruke

5. **Command Line Interface**
   - Argumenti za direktno pokretanje
   - Fleksibilna konfiguracija
   - Help komande

6. **Logging i Statistika**
   - Detaljni logovi u `logs/scraper.log`
   - Console output sa Rich
   - Statistika preuzimanja

## ğŸ¯ PodrÅ¾ani Izvori

### NauÄni Radovi
- **arXiv** - Fizika, matematika, raÄunarstvo
- **PubMed Central** - Biomedicina
- **SSRN** - DruÅ¡tvene nauke

### Knjige
- **Project Gutenberg** - Knjige u javnom domenu
- **Open Library** - Otvorena biblioteka

### ÄŒasopisi
- **Internet Archive** - Digitalni arhiv

### Custom
- MoguÄ‡nost dodavanja bilo kog URL-a

## ğŸ’» Kako Koristiti

### Osnovni Primeri

```powershell
# Interaktivni mod
python main.py --interactive

# Preuzimanje nauÄnih radova
python main.py --category research --source "arXiv" --query "AI" --limit 10

# Preuzimanje knjiga
python main.py --category books --source "Project Gutenberg" --query "fiction"

# Custom URL
python main.py --url "https://example.com/pdfs" --limit 20
```

### Napredna Konfiguracija

Uredi `.env` fajl:
```env
MAX_CONCURRENT_DOWNLOADS=5    # Broj istovremenih preuzimanja
DOWNLOAD_TIMEOUT=600          # Timeout u sekundama
OUTPUT_DIR=./moji_pdf         # Custom output direktorijum
```

## ğŸ”§ Tehnologije

- **Python 3.8+**
- **Crawlee 1.0.0** - Web scraping framework
- **Playwright** - Browser automation
- **aiohttp** - Async HTTP client
- **Rich** - Terminal formatting
- **BeautifulSoup** - HTML parsing
- **lxml** - XML/HTML parser

## ğŸ“Š Performanse

- âš¡ Async operacije za brze downloadove
- ğŸ¯ Kontrola konkurentnosti (default: 3 simultana)
- ğŸ”„ Automatski retry pri greÅ¡kama
- ğŸ’¾ Efikasno skladiÅ¡tenje

## ğŸ›¡ï¸ Validacije

- âœ“ URL validacija
- âœ“ PDF format provera (magic bytes)
- âœ“ VeliÄina fajla check
- âœ“ Content-Type provera

## ğŸ“ Logovanje

Logovi se Äuvaju na 2 nivoa:
1. **Console** - Lepo formatirano sa Rich (INFO level)
2. **File** - Detaljni logovi u `logs/scraper.log` (DEBUG level)

## ğŸ¨ Dodavanje Novih Izvora

1. Otvori `config/sources.py`
2. Dodaj novi `Source` objekat
3. DefiniÅ¡i CSS selektore
4. Gotovo!

Primer:
```python
Source(
    name="Novi Izvor",
    url="https://example.com",
    source_type=SourceType.RESEARCH,
    description="Opis",
    selectors={
        "search_url": "https://example.com/search?q={query}",
        "pdf_link": "a.download-pdf",
        "title": "h1.title",
    }
)
```

## ğŸ› Testiranje

```powershell
# Osnovni test
python test_basic.py

# Primer scraping-a
python example.py
```

## ğŸ“¦ Deploymentgung

Aplikacija je spremna za:
- Windows (testirano)
- Linux (trebalo bi da radi)
- macOS (trebalo bi da radi)

## ğŸ“ UÄenje i PrilagoÄ‘avanje

Aplikacija je dizajnirana da bude:
- **Modularna** - Lako dodavanje novih scrapers-a
- **ProÅ¡iriva** - Custom sources i kategorije
- **ÄŒitljiva** - Dobro dokumentovan kod
- **Testabilna** - Jasna struktura za testove

## ğŸš€ SledeÄ‡i Koraci

MoÅ¾ete dodati:
- [ ] Web UI (Flask/FastAPI)
- [ ] Database za metadata (SQLite)
- [ ] Scheduled scraping (APScheduler)
- [ ] Email notifikacije
- [ ] Docker container
- [ ] API endpoints
- [ ] PDF text extraction (PyPDF2)
- [ ] Full-text search (Elasticsearch)

## ğŸ“„ Licenca

MIT License - Slobodno koristite i menjajte!

## ğŸ¤ Kontribucije

Pull requests su dobrodoÅ¡li!

---

**âœ¨ UÅ¾ivajte u scraping-u! âœ¨**
